{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import model\n",
    "import data\n",
    "import torch\n",
    "import time\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "import json\n",
    "import utils\n",
    "import sklearn.preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "from git import Repo\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, unmix, device, train_sampler, optimizer):\n",
    "    losses = utils.AverageMeter()\n",
    "    unmix.train()\n",
    "    pbar = tqdm.tqdm(train_sampler, disable=args.quiet) \n",
    "    for x, y in pbar:\n",
    "        pbar.set_description(\"Training batch\")\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Y_hat = unmix(x)\n",
    "        Y = unmix.transform(y)\n",
    "        loss = torch.nn.functional.mse_loss(Y_hat, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.update(loss.item(), Y.size(1))\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(args, unmix, device, valid_sampler):\n",
    "    losses = utils.AverageMeter()\n",
    "    unmix.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_sampler:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            Y_hat = unmix(x)\n",
    "            Y = unmix.transform(y)\n",
    "            loss = torch.nn.functional.mse_loss(Y_hat, Y)\n",
    "            losses.update(loss.item(), Y.size(1))\n",
    "        return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(args, dataset):\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "    spec = torch.nn.Sequential(\n",
    "        model.STFT(n_fft=args.nfft, n_hop=args.nhop),\n",
    "        model.Spectrogram(mono=True)\n",
    "    )\n",
    "\n",
    "    dataset_scaler = copy.deepcopy(dataset)\n",
    "    dataset_scaler.samples_per_track = 1\n",
    "    dataset_scaler.augmentations = None\n",
    "    dataset_scaler.random_chunks = False\n",
    "    dataset_scaler.seq_duration = None\n",
    "    pbar = tqdm.tqdm(range(len(dataset_scaler)), disable=args.quiet)\n",
    "    for ind in pbar:\n",
    "        x, y = dataset_scaler[ind]\n",
    "        pbar.set_description(\"Compute dataset statistics\")\n",
    "        X = spec(x[None, ...])\n",
    "        scaler.partial_fit(np.squeeze(X))\n",
    "\n",
    "    # set inital input scaler values\n",
    "    std = np.maximum(\n",
    "        scaler.scale_,\n",
    "        1e-4*np.max(scaler.scale_)\n",
    "    )\n",
    "    return scaler.mean_, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--no-cuda'], dest='no_cuda', nargs=0, const=True, default=False, type=None, choices=None, help='disables CUDA training', metavar=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Open Unmix Trainer')\n",
    "\n",
    "# which target do we want to train?\n",
    "parser.add_argument('--target', type=str, default='vocals',\n",
    "                    help='target source (will be passed to the dataset)')\n",
    "\n",
    "# Dataset paramaters\n",
    "parser.add_argument('--dataset', type=str, default=\"musdb\",\n",
    "                    choices=[\n",
    "                        'musdb', 'aligned', 'sourcefolder',\n",
    "                        'trackfolder_var', 'trackfolder_fix'\n",
    "                    ],\n",
    "                    help='Name of the dataset.')\n",
    "parser.add_argument('--root', type=str, help='root path of dataset' , default='../rec_data/')\n",
    "parser.add_argument('--output', type=str, default=\"../out_unmix/\",\n",
    "                    help='provide output path base folder name')\n",
    "parser.add_argument('--model', type=str, help='Path to checkpoint folder', default='../checkpoint_unmix')\n",
    "\n",
    "# Trainig Parameters\n",
    "parser.add_argument('--epochs', type=int, default=1000)\n",
    "parser.add_argument('--batch-size', type=int, default=16)\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='learning rate, defaults to 1e-3')\n",
    "parser.add_argument('--patience', type=int, default=140,\n",
    "                    help='maximum number of epochs to train (default: 140)')\n",
    "parser.add_argument('--lr-decay-patience', type=int, default=80,\n",
    "                    help='lr decay patience for plateau scheduler')\n",
    "parser.add_argument('--lr-decay-gamma', type=float, default=0.3,\n",
    "                    help='gamma of learning rate scheduler decay')\n",
    "parser.add_argument('--weight-decay', type=float, default=0.00001,\n",
    "                    help='weight decay')\n",
    "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
    "                    help='random seed (default: 42)')\n",
    "\n",
    "\n",
    "# Model Parameters\n",
    "parser.add_argument('--seq-dur', type=float, default=6.0,\n",
    "                    help='Sequence duration in seconds'\n",
    "                    'value of <=0.0 will use full/variable length')\n",
    "parser.add_argument('--unidirectional', action='store_true', default=False,\n",
    "                    help='Use unidirectional LSTM instead of bidirectional')\n",
    "parser.add_argument('--nfft', type=int, default=4096,\n",
    "                    help='STFT fft size and window size')\n",
    "parser.add_argument('--nhop', type=int, default=1024,\n",
    "                    help='STFT hop size')\n",
    "parser.add_argument('--hidden-size', type=int, default=512,\n",
    "                    help='hidden size parameter of dense bottleneck layers')\n",
    "parser.add_argument('--bandwidth', type=int, default=16000,\n",
    "                    help='maximum model bandwidth in herz')\n",
    "parser.add_argument('--nb-channels', type=int, default=2,\n",
    "                    help='set number of channels for model (1, 2)')\n",
    "parser.add_argument('--nb-workers', type=int, default=0,\n",
    "                    help='Number of workers for dataloader.')\n",
    "\n",
    "# Misc Parameters\n",
    "parser.add_argument('--quiet', action='store_true', default=False,\n",
    "                    help='less verbose during training')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n",
      "Using Torchaudio:  False\n"
     ]
    }
   ],
   "source": [
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "print(\"Using GPU:\", use_cuda)\n",
    "print(\"Using Torchaudio: \", utils._torchaudio_available())\n",
    "dataloader_kwargs = {'num_workers': args.nb_workers, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "repo_dir = os.path.abspath(os.path.dirname('/media/Sharedata/aniruddha/source_sep_net/train.py'))\n",
    "repo = Repo(repo_dir)\n",
    "commit = repo.head.commit.hexsha[:7]\n",
    "\n",
    "# use jpg or npy\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument --is-wav: conflicting option string: --is-wav",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4035d2ed470f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Sharedata/aniruddha/source_sep_net/data.py\u001b[0m in \u001b[0;36mload_datasets\u001b[0;34m(parser, args)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'musdb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         parser.add_argument('--is-wav', action='store_true', default=False,\n\u001b[0;32m--> 193\u001b[0;31m                             help='loads wav instead of STEMS')\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--samples-per-track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         parser.add_argument(\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"length of metavar tuple does not match nargs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_argument_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1722\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption_strings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_positionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ArgumentGroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;31m# resolve any conflicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_conflict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m         \u001b[0;31m# add to actions list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_check_conflict\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m             \u001b[0mconflict_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m             \u001b[0mconflict_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_handle_conflict_error\u001b[0;34m(self, action, conflicting_actions)\u001b[0m\n\u001b[1;32m   1521\u001b[0m                                      \u001b[0;32mfor\u001b[0m \u001b[0moption_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m                                      in conflicting_actions])\n\u001b[0;32m-> 1523\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconflict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument --is-wav: conflicting option string: --is-wav"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset, args = data.load_datasets(parser, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
